{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from collections import deque,defaultdict\n",
    "import itertools\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "Number of actions:  3\n",
      "State space: [array([-1.20000005, -0.07      ], dtype=float32), array([ 0.60000002,  0.07      ], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('MountainCar-v0')\n",
    "env.reset()\n",
    "num_actions = env.action_space.n\n",
    "print('Number of actions: ', num_actions)\n",
    "state_low = env.observation_space.low\n",
    "state_high = env.observation_space.high\n",
    "print('State space:', [state_low, state_high])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Parameter initialization\n",
    "epsilon = 0.5\n",
    "γ= 0.95\n",
    "α = 0.1\n",
    "done_penalty = -10.0 #For CartPole\n",
    "\n",
    "smoothing_value = 0.1\n",
    "#max_steps = 10000\n",
    "max_len_hist = 20000\n",
    "number_of_neighbours = max_len_hist\n",
    "state_hist = dict([[i,deque(maxlen=max_len_hist)] for i in range(env.action_space.n)])\n",
    "srs_hist = dict([[i,deque(maxlen=max_len_hist)] for i in range(env.action_space.n)])\n",
    "\n",
    "#Start of learning loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s_ini = env.reset()\n",
    "returns_episode = []\n",
    "returns_episode_i = 0.0\n",
    "episode_len = 0\n",
    "for steps in range(max_len_hist):\n",
    "    episode_len += 1\n",
    "    #Taking a step in the environment\n",
    "    #action = np.random.choice([np.random.choice(env.action_space.n),np.argmax(Q_sa[tuple(s_ini)])], p=[epsilon,1-epsilon])\n",
    "    action = np.random.choice(env.action_space.n)\n",
    "    s_next, reward, done ,_ = env.step(action)  \n",
    "    #Computing return and updating memory\n",
    "    #returns_episode_i += reward \n",
    "    if not done:\n",
    "        srs_hist[action].append([s_ini,reward,s_next]) \n",
    "        state_hist[action].append(s_ini)\n",
    "        s_ini = s_next\n",
    "    else:\n",
    "        srs_hist[action].append([s_ini,reward,s_next]) \n",
    "        state_hist[action].append(s_ini)\n",
    "        #if episode_len < 199: #Gym Specific, since 200 is forced termination\n",
    "        #    srs_hist[action].append([s_next,done_penalty,'done']) \n",
    "        #    state_hist[action].append(s_next)\n",
    "        srs_hist[action].append([s_next,done_penalty,'done']) \n",
    "        state_hist[action].append(s_next)\n",
    "        s_ini = env.reset()\n",
    "        episode_len = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sre/gandharv/.local/lib/python3.5/site-packages/ipykernel_launcher.py:12: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "ks_a=dict([[i,deque(maxlen=max_len_hist)] for i in range(env.action_space.n)])\n",
    "indices = [0] + list(np.cumsum([len(state_hist[i]) for i in range(env.action_space.n)]))[:-1]\n",
    "all_states = list(itertools.chain(*[list(state_hist[i]) for i in range(env.action_space.n)]))\n",
    "all_srs = list(itertools.chain(*[list(srs_hist[i]) for i in range(env.action_space.n)]))\n",
    "P = [np.zeros((len(all_states),len(all_states))) for _ in range(env.action_space.n)]\n",
    "R = [np.zeros(len(all_states)) for _ in range(env.action_space.n)]\n",
    "for a in range(env.action_space.n):\n",
    "    neigh = NearestNeighbors(n_neighbors=min(number_of_neighbours, len(state_hist[a])))\n",
    "    ks_a[a] = neigh.fit([i.tolist() for i in state_hist[a]]) \n",
    "    for i in range(len(all_states)):\n",
    "        sprime = all_srs[i][2]\n",
    "        if sprime != 'done':\n",
    "            info = ks_a[a].kneighbors(sprime.reshape(1,-1))\n",
    "            weights = 1.0/(info[0][0]+smoothing_value)\n",
    "            weights /= weights.sum()\n",
    "            index_i = [j+indices[a] for j in info[1][0]]\n",
    "            P[a][i][index_i]= weights\n",
    "            R[a][i] = np.sum(P[a][i][index_i]*np.array([k[1] for k in np.array(all_srs)[index_i]]))\n",
    "        else:\n",
    "            P[a][i][i] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def VI(P_all, R_all, gamma, tau = 1e-10):\n",
    "    V = np.zeros(P_all.shape[1])\n",
    "    for i in range(1000):\n",
    "        V_old = np.copy(V)\n",
    "        Q = R_all + gamma*np.dot(P_all, V).reshape(R_all.shape, order='F')\n",
    "        V = np.max(Q, axis=1)\n",
    "        policy = np.argmax(R_all + gamma*np.dot(P_all, V).reshape(R_all.shape, order='F'), axis=1)\n",
    "        error = np.linalg.norm(V-V_old, 2)\n",
    "        if error < tau:\n",
    "            print('Converged after {:} iterations with error {:}'.format(i+1, error))\n",
    "            break\n",
    "    #print('Optimal Values:',V)\n",
    "    #print('Optimal Policy:',policy)\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged after 499 iterations with error 9.544996434370427e-11\n"
     ]
    }
   ],
   "source": [
    "Q = VI(np.concatenate(P, axis=0), np.array(R).T, γ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sre/gandharv/.local/lib/python3.5/site-packages/ipykernel_launcher.py:25: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n"
     ]
    }
   ],
   "source": [
    "γ= 0.95\n",
    "number_of_neighbours = 100\n",
    "smoothing_value = 0.0\n",
    "max_steps = 10000\n",
    "\n",
    "#Start of learning loop\n",
    "s_ini = env.reset()\n",
    "returns_episode = []\n",
    "returns_episode_i = 0.0\n",
    "\n",
    "for steps in range(max_steps): \n",
    "    #Taking a step in the environment\n",
    "    q = np.zeros(env.action_space.n)\n",
    "    for a in range(env.action_space.n):\n",
    "        #compute weights\n",
    "        info = ks_a[a].kneighbors(s_ini.reshape(1,-1))[:number_of_neighbours]\n",
    "        weights = 1.0/(info[0][0]+smoothing_value)\n",
    "        weights /= weights.sum()\n",
    "        #compute q_targets for each neighbour\n",
    "        q_target = 0.0\n",
    "        for i in range(len(weights)):\n",
    "            nbr = info[1][0][i]\n",
    "            r = srs_hist[a][nbr][1]\n",
    "            sprime = srs_hist[a][nbr][2]\n",
    "            if sprime != 'done':\n",
    "                q_target += weights[i]*(r+γ*Q[nbr+indices[a]].max())\n",
    "            else:\n",
    "                q_target += weights[i]*(r)\n",
    "        #compute bellman update and assign it to q\n",
    "        q[a] = q_target\n",
    "    action = np.argmax(q)\n",
    "    s_next, reward, done ,_ = env.step(action)\n",
    "    \n",
    "    #Computing return\n",
    "    returns_episode_i += reward\n",
    "    if not done:\n",
    "        s_ini = s_next\n",
    "    else:\n",
    "        s_ini = env.reset()\n",
    "        returns_episode.append(returns_episode_i)\n",
    "        returns_episode_i = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Return')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZoAAAEKCAYAAAArYJMgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(returns_episode)\n",
    "plt.xlabel('episodes')\n",
    "plt.ylabel('Return')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Discussion:\n",
    "\n",
    "Here we implement the KBRL algorithm for the mountain car environment in open-ai gym. As it can be seen from the results, the algorithm as mentioned by Ormoneit and Sen, 2002 doesnt seem to work for this environment. The main reason for this is that the reward signal in this environmemnt is very sparse and the inital model learning is heavily dependent on the portions of the state space the agent visits. As a result the agent fails to learn the model of the environment. To solve this problem using KBRL one can use some domain information like knowing the final state of the environment and letting the agent act in the environment till it reaches the final state. Further we can only retain the the transitions where the agent reached the goal state and try to learn the model using this data and/or use reward shaping."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL",
   "language": "python",
   "name": "rl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
